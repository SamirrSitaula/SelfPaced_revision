{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ce6c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#acquisition\n",
    "#importing data from local repo\n",
    "#Data Source: https://www.kaggle.com/datasets/blastchar/telco-customer-churn\n",
    "\n",
    "import pandas as pd\n",
    "#load the dataset\n",
    "#read the dataset\n",
    "\n",
    "df = pd.read_csv('/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/data/raw/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "#generate first five rows\n",
    "df.head()\n",
    "\n",
    "#basic information\n",
    "df.info()\n",
    "\n",
    "#data description\n",
    "df.describe()\n",
    "\n",
    "#shape of datasets(no. of rows and columns)\n",
    "df.shape\n",
    "\n",
    "#checking for missing \n",
    "df.isnull().sum()\n",
    "\n",
    "#checking for duplicates\n",
    "df.duplicated().sum()\n",
    "\n",
    "\n",
    "#data preview of the targeted columns\n",
    "df['Churn'].value_counts()\n",
    "\n",
    "df['MonthlyCharges'].describe()\n",
    "\n",
    "df['TotalCharges'].describe()\n",
    "\n",
    "# Perform acquisition tasks\n",
    "df.to_csv('/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/data/processed/acquired_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d21c5d17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cleaning\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/data/processed/acquired_data.csv')\n",
    "\n",
    "# Perform cleaning tasks\n",
    "df = df.dropna() \n",
    "\n",
    "\n",
    "\n",
    "# Drop the customerID column as it's not needed for prediction\n",
    "df.drop('customerID', axis=1, inplace=True)\n",
    "\n",
    "# Convert 'TotalCharges' to numeric, forcing errors to NaN (i.e., invalid data)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Drop rows where 'TotalCharges' is NaN (invalid values after conversion)\n",
    "df.dropna(subset=['TotalCharges'], inplace=True)\n",
    "\n",
    "# Replace any remaining spaces with NaN\n",
    "df.replace(\" \", pd.NA, inplace=True)\n",
    "\n",
    "# Drop any duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Reset the index after cleaning\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Show the cleaned data\n",
    "df.head()\n",
    "\n",
    "#save the cleaned file\n",
    "df.to_csv('/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/data/processed/cleaned_data.csv', index=False)\n",
    "df.to_csv(\"/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/data/processed/final_dataset_with_clv.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a46e37-bcf8-44ac-8fee-f9bd943ba7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure',\n",
      "       'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
      "       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
      "       'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod',\n",
      "       'MonthlyCharges', 'TotalCharges', 'Churn'],\n",
      "      dtype='object')\n",
      "['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges', 'Churn', 'monthly_charges_tenure', 'monthly_charges_squared', 'total_charges_squared', 'gender_Male', 'Partner_Yes', 'Dependents_Yes', 'PhoneService_Yes', 'MultipleLines_No phone service', 'MultipleLines_Yes', 'InternetService_Fiber optic', 'InternetService_No', 'OnlineSecurity_No internet service', 'OnlineSecurity_Yes', 'OnlineBackup_No internet service', 'OnlineBackup_Yes', 'DeviceProtection_No internet service', 'DeviceProtection_Yes', 'TechSupport_No internet service', 'TechSupport_Yes', 'StreamingTV_No internet service', 'StreamingTV_Yes', 'StreamingMovies_No internet service', 'StreamingMovies_Yes', 'Contract_One year', 'Contract_Two year', 'PaperlessBilling_Yes', 'PaymentMethod_Credit card (automatic)', 'PaymentMethod_Electronic check', 'PaymentMethod_Mailed check']\n"
     ]
    }
   ],
   "source": [
    "#feature Engineering\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Load the cleaned dataset (assuming it's already cleaned and saved in 'processed')\n",
    "df = pd.read_csv('/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/data/processed/cleaned_data.csv')\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "#Interaction terms(mmonthly charges and Tenure to capture how the cost and duration of the customers contract affect churn)\n",
    "df['monthly_charges_tenure'] = df['MonthlyCharges'] * df['tenure']\n",
    "\n",
    "#new features 'polynomila features generated by taking the existing features and raising them to a power or multiplying together,  to see non linear relationships\n",
    "\n",
    "df['monthly_charges_squared'] = df['MonthlyCharges'] ** 2\n",
    "df['total_charges_squared'] = df['TotalCharges'] ** 2\n",
    "\n",
    "#categorical encoding(one hot encodings) to convert into numerical formats\n",
    "df = pd.get_dummies(df, columns=['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', \n",
    "                                 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                                 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', \n",
    "                                 'PaperlessBilling', 'PaymentMethod'], drop_first=True)\n",
    "\n",
    "\n",
    "#handling missing values\n",
    "# Fill missing numerical columns with the median value\n",
    "df['TotalCharges'] = df['TotalCharges'].replace(' ', np.nan)  # Replace empty strings with NaN\n",
    "df['TotalCharges'] = df['TotalCharges'].astype(float)\n",
    "\n",
    "#filled by median\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
    "\n",
    "\n",
    "# Fill missing categorical columns with the mode\n",
    "df['SeniorCitizen'] = df['SeniorCitizen'].fillna(df['SeniorCitizen'].mode()[0])\n",
    "\n",
    "print(df.columns.tolist())\n",
    "\n",
    "#feature grouping to group related features for easy analysis\n",
    "#grouping streaming services and streamingMovies into single feature\n",
    "df['has_streaming_services'] = ((df['StreamingTV_Yes'] == 1) | (df['StreamingMovies_Yes'] == 1)).astype(int)\n",
    "\n",
    "\n",
    "#grouping for online securities and device protections\n",
    "df['has_online_security_or_protection'] = (\n",
    "    (df['OnlineSecurity_Yes'] == 1) | (df['DeviceProtection_Yes'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "#scaling features\n",
    "#ensure that no single feature dominates due to scale differences\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[['MonthlyCharges', 'TotalCharges', 'tenure']] = scaler.fit_transform(df[['MonthlyCharges', 'TotalCharges', 'tenure']])\n",
    "\n",
    "#Feature Engineering for customer segmentation\n",
    "#use target column to divide the dataset into churned and non-churned customers.\n",
    "df['tenure_segment'] = pd.cut(df['tenure'], bins=[0, 12, 24, 36, 48, np.inf], labels=['0-1 year', '1-2 years', '2-3 years', '3-4 years', '4+ years'])\n",
    "\n",
    "df['monthly_charge_segment'] = pd.cut(df['MonthlyCharges'], bins=[0, 30, 60, 90, np.inf], labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "\n",
    "#creating new target features for analysis\n",
    "df['churn_contract'] = (df['Churn'] == 'Yes') & \\\n",
    "                       (df['Contract_One year'] == 0) & \\\n",
    "                       (df['Contract_Two year'] == 0)\n",
    "df['churn_contract'] = df['churn_contract'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "def create_clv_target(df, monetary_column='TotalCharges', time_column='tenure'):\n",
    "    \"\"\"\n",
    "    Creates a simple CLV target variable using:\n",
    "    CLV = Average Monthly Spend * Tenure\n",
    "    \"\"\"\n",
    "    df['CLV'] = df[monetary_column] / df[time_column].replace(0, 1) * df[time_column]\n",
    "    return df\n",
    "df = create_clv_target(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0753005f-3337-4045-8ddc-1daeaec59abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender              object\n",
      "Partner             object\n",
      "Dependents          object\n",
      "PhoneService        object\n",
      "MultipleLines       object\n",
      "InternetService     object\n",
      "OnlineSecurity      object\n",
      "OnlineBackup        object\n",
      "DeviceProtection    object\n",
      "TechSupport         object\n",
      "StreamingTV         object\n",
      "StreamingMovies     object\n",
      "Contract            object\n",
      "PaperlessBilling    object\n",
      "PaymentMethod       object\n",
      "dtype: object\n",
      "=== Logistic Regression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.88      0.90      0.89      1081\n",
      "         Yes       0.62      0.58      0.60       321\n",
      "\n",
      "    accuracy                           0.82      1402\n",
      "   macro avg       0.75      0.74      0.74      1402\n",
      "weighted avg       0.82      0.82      0.82      1402\n",
      "\n",
      "ROC-AUC: 0.8518102253307627\n",
      "\n",
      "=== Random Forest ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.88      0.87      1081\n",
      "         Yes       0.55      0.48      0.51       321\n",
      "\n",
      "    accuracy                           0.79      1402\n",
      "   macro avg       0.70      0.68      0.69      1402\n",
      "weighted avg       0.78      0.79      0.79      1402\n",
      "\n",
      "ROC-AUC: 0.8190019625303673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "Train Accuracy: 0.8021, Test Accuracy: 0.8210\n",
      "Train ROC-AUC: 0.8470, Test ROC-AUC: 0.8517\n",
      "Train Accuracy: 0.8217, Test Accuracy: 0.7675\n",
      "Train ROC-AUC:  0.9180, Test ROC-AUC:  0.8477\n",
      "\n",
      "⚠️ Likely Overfitting: High gap between train and test ROC-AUC.\n",
      "Cross-validated ROC-AUC: 0.8423 ± 0.0112\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Load your processed dataset (if you're reading from file)\n",
    "# df = pd.read_csv('data/processed/your_file.csv')\n",
    "\n",
    "\n",
    "df = pd.read_csv('/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/data/processed/cleaned_data.csv')\n",
    "\n",
    "# 1. Feature-target split\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Save test sets\n",
    "X_test.to_csv(\"/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/data/processed/X_test.csv\", index=False)\n",
    "y_test.to_csv(\"/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/data/processed/y_test.csv\", index=False)\n",
    "\n",
    "#check for object(non- numeric column)\n",
    "print(X_train.dtypes[X_train.dtypes == 'object'])\n",
    "\n",
    "#convert to numeric columns\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "# Align test set columns with train\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Save the training columns (feature names) so you can align test data later\n",
    "pd.Series(X_train.columns).to_csv(\n",
    "    '/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/data/processed/X_train_columns.csv',\n",
    "    index=False,\n",
    "    header=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Scaling (Optional but good for models like Logistic Regression)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Model Training\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)  # RF doesn't need scaling\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5. Evaluation\n",
    "print(\"=== Logistic Regression ===\")\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, log_reg.predict_proba(X_test_scaled)[:, 1]))\n",
    "\n",
    "print(\"\\n=== Random Forest ===\")\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "# 6. Save best model\n",
    "joblib.dump(rf, '/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/models/random_forest_model.pkl')\n",
    "joblib.dump(log_reg, '/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/models/logistic_model.pkl')\n",
    "joblib.dump(scaler, '/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/models/scaler.pkl')\n",
    "\n",
    "\n",
    "\n",
    "def train_clv_model(X_train, y_train, model_type='random_forest'):\n",
    "    if model_type == 'random_forest':\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    elif model_type == 'linear':\n",
    "        model = LinearRegression()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type\")\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "#overfitting and underfitting\n",
    "\n",
    "#Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "train_preds = lr_model.predict(X_train)\n",
    "test_preds = lr_model.predict(X_test)\n",
    "\n",
    "# Accuracy and AUC\n",
    "train_acc = accuracy_score(y_train, train_preds)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "\n",
    "train_auc = roc_auc_score(y_train, lr_model.predict_proba(X_train)[:, 1])\n",
    "test_auc = roc_auc_score(y_test, lr_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Output\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Train ROC-AUC: {train_auc:.4f}, Test ROC-AUC: {test_auc:.4f}\")\n",
    "\n",
    "#  for Random Forest \n",
    "\n",
    "\n",
    "\n",
    "# 1. Define and train the model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,        # Number of trees\n",
    "    max_depth=10,            # Limit tree depth\n",
    "    min_samples_split=10,    # Minimum samples to split a node\n",
    "    min_samples_leaf=4,      # Minimum samples at a leaf node\n",
    "    max_features='sqrt',     # Random subset of features at each split\n",
    "    class_weight='balanced', # Handles imbalance\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Evaluate for overfitting or underfitting\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "y_train_proba = rf_model.predict_proba(X_train)[:, 1]\n",
    "y_test_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Train ROC-AUC:  {train_auc:.4f}, Test ROC-AUC:  {test_auc:.4f}\")\n",
    "\n",
    "# Diagnose\n",
    "if train_auc - test_auc > 0.05:\n",
    "    print(\"\\n⚠️ Likely Overfitting: High gap between train and test ROC-AUC.\")\n",
    "elif test_auc - train_auc > 0.05:\n",
    "    print(\"\\n⚠️ Possible Underfitting: Model generalizes better than it fits training data.\")\n",
    "else:\n",
    "    print(\"\\n✅ Good Fit: Train and test scores are close.\")\n",
    "\n",
    "\n",
    "#cross validation\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Cross-validated ROC-AUC: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1135ce28-22a1-4184-8e84-836c51e2ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "\n",
    "def ensure_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def preprocess_for_rf(X_raw, train_columns):\n",
    "    \"\"\"\n",
    "    Preprocess test data for Random Forest:\n",
    "    - One-hot encode categorical columns\n",
    "    - Align columns to training columns (add missing cols with zeros)\n",
    "    \"\"\"\n",
    "    X = pd.get_dummies(X_raw)\n",
    "    # Reindex to train columns, fill missing columns with 0\n",
    "    X = X.reindex(columns=train_columns, fill_value=0)\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_for_logreg(X_raw, train_columns, scaler):\n",
    "    \"\"\"\n",
    "    Preprocess test data for Logistic Regression:\n",
    "    - One-hot encode categorical columns\n",
    "    - Align columns to training columns\n",
    "    - Scale using pre-fitted scaler\n",
    "    \"\"\"\n",
    "    X = pd.get_dummies(X_raw)\n",
    "    X = X.reindex(columns=train_columns, fill_value=0)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"model\"):\n",
    "    \"\"\"\n",
    "    Evaluates the model, prints metrics, plots confusion matrix and ROC curve,\n",
    "    saves classification report CSV and plots to outputs folder.\n",
    "    \"\"\"\n",
    "    # Ensure output dirs\n",
    "    report_dir = \"/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/reports\"\n",
    "    figures_dir = \"/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/figures\"\n",
    "    ensure_dir(report_dir)\n",
    "    ensure_dir(figures_dir)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = pd.Series(y_pred).map({'No': 0, 'Yes': 1}).values\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_prob = None\n",
    "\n",
    "    # Print classification report\n",
    "    print(f\"\\n=== Evaluation Report: {model_name} ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    if y_prob is not None:\n",
    "        roc_auc = roc_auc_score(y_test, y_prob)\n",
    "        print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "    else:\n",
    "        roc_auc = None\n",
    "        print(\"ROC-AUC Score: Not available (no predict_proba method)\")\n",
    "\n",
    "    # Save classification report as CSV\n",
    "    report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "    df_report = pd.DataFrame(report_dict).transpose()\n",
    "    report_path = os.path.join(report_dir, f\"{model_name.lower().replace(' ', '_')}_classification_report.csv\")\n",
    "    df_report.to_csv(report_path)\n",
    "    print(f\"Saved classification report to {report_path}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"{model_name} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    cm_path = os.path.join(figures_dir, f\"{model_name.lower().replace(' ', '_')}_confusion_matrix.png\")\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix plot to {cm_path}\")\n",
    "\n",
    "    # Plot ROC curve \n",
    "    if y_prob is not None:\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(6,5))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'{model_name} Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        roc_path = os.path.join(figures_dir, f\"{model_name.lower().replace(' ', '_')}_roc_curve.png\")\n",
    "        plt.savefig(roc_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved ROC curve plot to {roc_path}\")\n",
    "\n",
    "#clv_model\n",
    "\n",
    "\n",
    "def evaluate_clv_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R²: {r2:.2f}\")\n",
    "\n",
    "    # Save figure\n",
    "    figures_dir = \"/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/figures\"\n",
    "    reports_dir = \"/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/reports\"\n",
    "    os.makedirs(figures_dir, exist_ok=True)\n",
    "    os.makedirs(reports_dir, exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=y_test, y=y_pred, alpha=0.5)\n",
    "    plt.xlabel(\"Actual CLV\")\n",
    "    plt.ylabel(\"Predicted CLV\")\n",
    "    plt.title(\"Actual vs Predicted CLV\")\n",
    "    plt.savefig(f\"{figures_dir}/clv_actual_vs_predicted.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # Save evaluation report as CSV\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': ['MAE', 'RMSE', 'R2'],\n",
    "        'Value': [mae, rmse, r2]\n",
    "    })\n",
    "    csv_path = f\"{reports_dir}/clv_regression_report.csv\"\n",
    "    metrics_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved CLV regression report to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f25276b-1073-46c1-ad86-79c4c01a711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation Report: Random Forest ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87      1081\n",
      "           1       0.55      0.48      0.51       321\n",
      "\n",
      "    accuracy                           0.79      1402\n",
      "   macro avg       0.70      0.68      0.69      1402\n",
      "weighted avg       0.78      0.79      0.79      1402\n",
      "\n",
      "ROC-AUC Score: 0.8190\n",
      "Saved classification report to /Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/reports/random_forest_classification_report.csv\n",
      "Saved confusion matrix plot to /Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/figures/random_forest_confusion_matrix.png\n",
      "Saved ROC curve plot to /Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/figures/random_forest_roc_curve.png\n",
      "\n",
      "=== Evaluation Report: Logistic Regression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      1081\n",
      "           1       0.62      0.58      0.60       321\n",
      "\n",
      "    accuracy                           0.82      1402\n",
      "   macro avg       0.75      0.74      0.74      1402\n",
      "weighted avg       0.82      0.82      0.82      1402\n",
      "\n",
      "ROC-AUC Score: 0.8518\n",
      "Saved classification report to /Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/reports/logistic_regression_classification_report.csv\n",
      "Saved confusion matrix plot to /Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/figures/logistic_regression_confusion_matrix.png\n",
      "Saved ROC curve plot to /Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/figures/logistic_regression_roc_curve.png\n"
     ]
    }
   ],
   "source": [
    "#script evaluation\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# from evaluation import evaluate_model, preprocess_for_rf, preprocess_for_logreg\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths (update if needed)\n",
    "    X_test_path = \"/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/data/processed/X_test.csv\"\n",
    "    y_test_path = \"/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/data/processed/y_test.csv\"\n",
    "    rf_model_path = \"/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/models/random_forest_model.pkl\"\n",
    "    logreg_model_path = \"/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/models/logistic_model.pkl\"\n",
    "    scaler_path = \"/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/models/scaler.pkl\"\n",
    "    train_columns_path = \"/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/data/processed/X_train_columns.csv\"\n",
    "\n",
    "    # Load test data\n",
    "    X_test_raw = pd.read_csv(X_test_path)\n",
    "    y_test = pd.read_csv(y_test_path).squeeze()\n",
    "    y_test = y_test.map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Convert y_test from 'No'/'Yes' to 0/1\n",
    "   \n",
    "\n",
    "    # Load models and scaler\n",
    "    rf_model = joblib.load(rf_model_path)\n",
    "    logreg_model = joblib.load(logreg_model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "\n",
    "    # Load train columns list for dummy alignment\n",
    "    train_columns = pd.read_csv(train_columns_path, header=None).squeeze().tolist()\n",
    "\n",
    "    # Preprocess test data for Random Forest and evaluate\n",
    "    X_test_rf = preprocess_for_rf(X_test_raw, train_columns)\n",
    "    evaluate_model(rf_model, X_test_rf, y_test, model_name=\"Random Forest\")\n",
    "\n",
    "    # Preprocess test data for Logistic Regression and evaluate\n",
    "    X_test_logreg = preprocess_for_logreg(X_test_raw, train_columns, scaler)\n",
    "    evaluate_model(logreg_model, X_test_logreg, y_test, model_name=\"Logistic Regression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11f2f115-0030-4998-8349-868c152de76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.97\n",
      "RMSE: 1.80\n",
      "R²: 1.00\n",
      "Saved CLV regression report to /Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/reports/clv_regression_report.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#evaluation_clv\n",
    "# Load processed data\n",
    "df = pd.read_csv(\"../data/processed/final_dataset_with_clv.csv\")\n",
    "\n",
    "def clean_data(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Handle missing or whitespace TotalCharges\n",
    "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Encode categorical variables if not done yet\n",
    "    if 'Contract' in df.columns:\n",
    "        df['Contract_encoded'] = df['Contract'].astype('category').cat.codes\n",
    "    if 'PaymentMethod' in df.columns:\n",
    "        df['PaymentMethod_encoded'] = df['PaymentMethod'].astype('category').cat.codes\n",
    "\n",
    "    return df\n",
    "\n",
    "# Optional: clean again (if needed)\n",
    "df = clean_data(df)\n",
    "df = create_features(df)\n",
    "df = create_clv_target(df)\n",
    "\n",
    "# Select features and target\n",
    "\n",
    "\n",
    "\n",
    "features = ['MonthlyCharges', 'tenure', 'TotalCharges', 'Contract_encoded', 'PaymentMethod_encoded']  # Add more as needed\n",
    "X = df[features]\n",
    "y = df['CLV']\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = train_clv_model(X_train, y_train, model_type='random_forest')\n",
    "\n",
    "# Evaluate\n",
    "evaluate_clv_model(model, X_test, y_test)\n",
    "\n",
    "# Predict values for residual plot\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " #saving regression model as csv   \n",
    "\n",
    "\n",
    "def evaluate_clv_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R²: {r2:.2f}\")\n",
    "\n",
    "    # Save figure\n",
    "    figures_dir = \"/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/figures\"\n",
    "    reports_dir = \"/Users/samirsitaula/Documents/Selfpaced_Practice/projects/customer_clv_churn/outputs/reports\"\n",
    "    os.makedirs(figures_dir, exist_ok=True)\n",
    "    os.makedirs(reports_dir, exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=y_test, y=y_pred, alpha=0.5)\n",
    "    plt.xlabel(\"Actual CLV\")\n",
    "    plt.ylabel(\"Predicted CLV\")\n",
    "    plt.title(\"Actual vs Predicted CLV\")\n",
    "    plt.savefig(f\"{figures_dir}/clv_actual_vs_predicted.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Save evaluation report as CSV\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': ['MAE', 'RMSE', 'R2'],\n",
    "        'Value': [mae, rmse, r2]\n",
    "    })\n",
    "    csv_path = f\"{reports_dir}/clv_regression_report.csv\"\n",
    "    metrics_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved CLV regression report to {csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0519bd9f-f19c-4631-9aa9-33dbd471d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Feature Importance Plot\n",
    "def plot_feature_importance(model, feature_names, output_path, model_name=\"model\"):\n",
    "    \"\"\"\n",
    "    Plots feature importance for tree-based models.\n",
    "    \"\"\"\n",
    "    importances = model.feature_importances_\n",
    "    feature_imp_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_imp_df)\n",
    "    plt.title(f'{model_name} Feature Importance')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved feature importance plot to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a919e09d-cc55-4a5c-80a4-19c4fa1aa3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge churn and prediction\n",
    "def merge_predictions(df, churn_preds, clv_preds):\n",
    "    df = df.copy()\n",
    "    df['Churn_Probability'] = churn_preds  # Probabilities (or binary)\n",
    "    df['Predicted_CLV'] = clv_preds\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f50765a-4f85-4ee6-9f12-65f48c99b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dashboard Summary Generator\n",
    "\n",
    "def generate_dashboard_summary(df, output_dir=\"outputs/figures\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Churn Distribution\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df['Churn_Probability'], bins=20, kde=True)\n",
    "    plt.title(\"Churn Probability Distribution\")\n",
    "    plt.xlabel(\"Churn Probability\")\n",
    "    plt.savefig(f\"{output_dir}/churn_distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # CLV Distribution\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df['Predicted_CLV'], bins=30, kde=True)\n",
    "    plt.title(\"Predicted CLV Distribution\")\n",
    "    plt.xlabel(\"CLV\")\n",
    "    plt.savefig(f\"{output_dir}/clv_distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # CLV vs Churn Probability\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.scatterplot(x='Churn_Probability', y='Predicted_CLV', data=df, alpha=0.5)\n",
    "    plt.title(\"CLV vs Churn Probability\")\n",
    "    plt.savefig(f\"{output_dir}/clv_vs_churn.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved all summary figures to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afa29f70-e5e9-416f-9149-e28880dc8a66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'churn_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_final \u001b[38;5;241m=\u001b[39m merge_predictions(df, churn_preds, clv_preds)\n\u001b[1;32m      2\u001b[0m df_final\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs/reports/final_dashboard_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'churn_preds' is not defined"
     ]
    }
   ],
   "source": [
    "df_final = merge_predictions(df, churn_preds, clv_preds)\n",
    "df_final.to_csv(\"outputs/reports/final_dashboard_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
